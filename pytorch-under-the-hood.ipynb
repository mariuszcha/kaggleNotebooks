{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mariuszcha/pytorch-under-the-hood?scriptVersionId=132790317\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"97ddedfb","metadata":{"papermill":{"duration":0.008205,"end_time":"2023-06-08T10:18:01.85503","exception":false,"start_time":"2023-06-08T10:18:01.846825","status":"completed"},"tags":[]},"source":["In the provided notebook, you will discover a PyTorch implementation and a clear numpy implementation for solving the MNIST dataset problem. Initially, binary classification is performed, and subsequently, it transitions into multi-class classification. One of the challenging aspects was comprehending the chain rule during the process of backward propagation. Understanding the construction of PyTorch classes is valuable for creating new classes in the future, extending the functionality of existing ones.\n","\n","\n","**Importing libraries...**"]},{"cell_type":"code","execution_count":1,"id":"7867a634","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:01.874136Z","iopub.status.busy":"2023-06-08T10:18:01.873389Z","iopub.status.idle":"2023-06-08T10:18:05.978678Z","shell.execute_reply":"2023-06-08T10:18:05.977134Z"},"papermill":{"duration":4.117748,"end_time":"2023-06-08T10:18:05.981702","exception":false,"start_time":"2023-06-08T10:18:01.863954","status":"completed"},"tags":[]},"outputs":[],"source":["# Basic ones\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Used to PyTorch approach\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","id":"268e4cf2","metadata":{"papermill":{"duration":0.005909,"end_time":"2023-06-08T10:18:05.99523","exception":false,"start_time":"2023-06-08T10:18:05.989321","status":"completed"},"tags":[]},"source":["**Data preparation...**"]},{"cell_type":"code","execution_count":2,"id":"d01f30a8","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:06.012973Z","iopub.status.busy":"2023-06-08T10:18:06.011931Z","iopub.status.idle":"2023-06-08T10:18:10.276819Z","shell.execute_reply":"2023-06-08T10:18:10.275503Z"},"papermill":{"duration":4.278693,"end_time":"2023-06-08T10:18:10.28019","exception":false,"start_time":"2023-06-08T10:18:06.001497","status":"completed"},"tags":[]},"outputs":[],"source":["data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n","\n","# We perform binary classification, so we select only records where label is 1 or 7.\n","fdata = data.loc[(data.label == 1)|(data.label == 7),:].copy()\n","\n","# In binary classification the labels should be 0 or 1; so we map these values to existing one Number 7 is label 0\n","# and Number 1 is 1.\n","fdata['label'].replace({1: 1, 7: 0}, inplace=True)\n","\n","# We have to divide our set into train and valid subsets, we do that in a proportion 80/20.\n","proportion = int(fdata.shape[0] * 0.8)\n","\n","# Splitting data...\n","X_train = fdata.iloc[:proportion,1:].values / 255.\n","X_valid = fdata.iloc[proportion:,1:].values / 255.\n","y_train = fdata.iloc[:proportion,0].values.reshape(-1,1)\n","y_valid = fdata.iloc[proportion:,0].values.reshape(-1,1)\n","\n","# Here we prepare data for PyTorch model. PyTorch require tensors. Tensor is basically Matrix or Array but in PyTorch\n","# nomenclature.\n","X_train_t, X_valid_t, y_train_t, y_valid_t = map(torch.Tensor, (X_train, X_valid, y_train, y_valid))"]},{"cell_type":"code","execution_count":3,"id":"cae37e06","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:10.295681Z","iopub.status.busy":"2023-06-08T10:18:10.29435Z","iopub.status.idle":"2023-06-08T10:18:10.302877Z","shell.execute_reply":"2023-06-08T10:18:10.301472Z"},"papermill":{"duration":0.018643,"end_time":"2023-06-08T10:18:10.30524","exception":false,"start_time":"2023-06-08T10:18:10.286597","status":"completed"},"tags":[]},"outputs":[],"source":["# Here we define some parameters - both for our PyTorch approach and Numpy approach\n","input_size = X_train.shape[1]\n","hidden_size = 32\n","output_size = 1\n","epochs = 20\n","batch = 128\n","lr = 0.01"]},{"cell_type":"markdown","id":"10225dd9","metadata":{"papermill":{"duration":0.005402,"end_time":"2023-06-08T10:18:10.318955","exception":false,"start_time":"2023-06-08T10:18:10.313553","status":"completed"},"tags":[]},"source":["# Numpy approach:\n","\n","Here, in the numpy approach, we define new classes such as Linear, ReLU, Sigmoid, and MAE (our loss function). These classes are designed to encapsulate specific operations and calculations within our model. By implementing the `__call__` method, we enable easy invocation of these objects as if they were functions.\n","\n","The key aspect is the `backward` method, which plays a vital role in calculating gradients during the backward propagation step. It enables the flow of gradients through the network, allowing us to update the model's parameters based on the loss.\n","\n","In summary, the numpy approach involves creating specialized classes that encapsulate different operations in the model. The `__call__` method allows these objects to be easily invoked, while the `backward` method is responsible for computing gradients and facilitating the backward propagation process.\n","\n","The Model class is responsible for defining the architecture of our model. By encapsulating the architecture within a class, we can easily add new hidden layers and customize the structure of our neural network.\n","\n","In order to train our model, we define a simple fit function that performs the backward propagation through multiple epochs. This function allows our neural network to learn from the data and update its parameters based on the defined loss function and optimization algorithm.\n","\n","By organizing the model architecture and training process within the Model class, we can easily create instances of the model, customize its structure, and train it on different datasets. This approach provides a modular and flexible way to build and train neural networks.\n","\n","Useful resources to backward propagation and calculation of gradients:\n","* [https://cs231n.github.io/optimization-2/](http://)\n","* [https://www.youtube.com/watch?v=Ilg3gGewQ5U](http://)\n","* [https://www.youtube.com/watch?v=tIeHLnjs5U8](http://)\n","* FSDL Course\n","\n","**Some good questions...**\n","\n","1. Why we multiply weights and biases by learning rate?\n","* The purpose of multiplying the gradients by the learning rate is to control the magnitude of the update. \n","If the learning rate is too high, the updates to the parameters can be too large, causing the optimization process to overshoot the optimal solution and potentially lead to instability or divergence. On the other hand, if the learning rate is too low, the updates can be too small, leading to slow convergence and potentially getting stuck in suboptimal solutions.\n","\n","2. How we calculate gradients and how it works?\n","* The first link above is fantastic explanation of importance of backpropagation and how exacly it works. Basically our architecture looks like this: INPUT -> HIDDEN LAYER(LINEAR1) -> ACTIVATION FUNCTION(RELU) -> HIDDEN LAYER(LINEAR 2) -> ACTIVATION FUNCTION(SIGMOID) -> OUTPUT LAYER - where we calculate Loss Function, in that situation it's MAE Error. For each of that steps we have to calculate gradient. Starting with MAE -> SIGMOID -> LINEAR 2 -> RELU -> LINEAR 1. We have to perform all of that calcs in order to update weights in biases in both Linear layers.\n","##### Let's start with LOSS(MAE):\n","Formula: **SUM(y_pred - y_true) / n**, where n number of samples\\\n","Gradient: **SIGN(y_pred - y_true) / n**\n","\n","In the gradient of MAE, we use the sign function to determine the direction of the gradient based on the difference between the predicted values and the true values. If the predicted value is greater than the true value, the difference will be positive, and the sign function will return 1, indicating that we need to decrease the predicted value. If the predicted value is smaller than the true value, the difference will be negative, and the sign function will return -1, indicating that we need to increase the predicted value.\n","\n","By multiplying the sign of the difference with 1/n, we obtain the scaled gradient that points in the direction that minimizes the absolute difference between the predicted values and the true values. This scaled gradient is then used to update the parameters of the model during the optimization process.\n","\n","##### Sigmoid:\n","Formula: **f = 1 /(1 + exp(-x))** \\\n","Gradient: **(1 - f) * f**\n","\n","In the first link (cs231) we can find perfect explanation of Sigmoid Gradient and how to simpify it to so basic form.\n","\n","##### ReLU:\n","Formula: **MAX(x, 0)** \\\n","Gradient: **x > 0** \\\n","When differentiating the ReLU function, we only consider the case when x > 0 because the derivative of ReLU is constant and equal to 1 for positive values of x. For x <= 0, the derivative is 0, so the gradient is 0 in those cases. Therefore, the gradient of ReLU can be expressed as a Boolean mask (x > 0) that returns 1 if x > 0 and 0 otherwise. This simple gradient computation can be found in resources like the cs231n course notes.\n","\n","##### Linear:\n","Formula: **y = wx + b** \\\n","Gradient: \\\n","dy/dx = w, gradient of x as our output in Chain Rule\\\n","dy/dw = x, gradient for weight\\\n","dy/db = 1, gradienf for bias\\\n","\n","Calculating gradients for Linear model we have three of them. dy/dw and dy/db are actual gradients used to update weights and biases in specific layer where dy/dx is output used in Chain Rule.\\\n","As the name says - it is called Chain Rule - so each layer must be connected with other one. Basically the gradients flow thru our model to first hidden layer...\n","\n","**Classes and functions...**"]},{"cell_type":"code","execution_count":4,"id":"60c77dc3","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:10.33359Z","iopub.status.busy":"2023-06-08T10:18:10.333091Z","iopub.status.idle":"2023-06-08T10:18:10.355996Z","shell.execute_reply":"2023-06-08T10:18:10.354653Z"},"papermill":{"duration":0.033791,"end_time":"2023-06-08T10:18:10.359053","exception":false,"start_time":"2023-06-08T10:18:10.325262","status":"completed"},"tags":[]},"outputs":[],"source":["class Linear:\n","    def __init__(self, input_size, hidden_size):\n","        # Initalization of weights and biases using Xavier Initalizer in constructor\n","        variance = 1 / (input_size + hidden_size)\n","        std_dev = np.sqrt(variance)\n","        self.weights = np.random.randn(input_size, hidden_size) * std_dev\n","        self.bias = np.zeros(hidden_size)\n","  \n","    def __call__(self, x):\n","        # Simple linear model\n","        self.x = x\n","        output = x @ self.weights + self.bias\n","        return output\n","\n","    def backward(self, input_gradient):\n","        # It is important to remember about proper shapes during multiplying. We can check them using .shape\n","        self.weights_gradient = self.x.T @ input_gradient\n","        self.bias_gradient = input_gradient.sum(axis=0)\n","        output_gradient = input_gradient @ self.weights.T\n","        return output_gradient\n","\n","    def update(self, lr):\n","        self.weights -= lr * self.weights_gradient\n","        self.bias -= lr * self.bias_gradient\n","        \n","class ReLU:\n","    def __call__(self, x):\n","        self.x = x\n","        return np.maximum(x, 0)\n","    \n","    def backward(self, input_gradient):\n","        output_gradient = input_gradient * (self.x > 0)\n","        return output_gradient\n","        \n","class MAE:\n","    def __call__(self, y_pred, y_true):\n","        self.y_pred = y_pred\n","        self.y_true = y_true\n","        return np.mean(np.abs(y_pred - y_true))\n","\n","    def backward(self):\n","        n = self.y_true.shape[0]\n","        output_gradient = np.sign(self.y_pred - self.y_true) / n\n","        return output_gradient\n","    \n","class Sigmoid():\n","    def __call__(self, x):\n","        self.x = x\n","        return 1 / (1 + np.exp(-self.x))\n","    \n","    def backward(self, input_gradient):\n","        # At the beginning I had small problem with coding that backward prop for sigmoid. However we can use very clever\n","        # class feature. This line of code calculates the sigmoid value for the input self.x and assigns it to the \n","        # sigmoid_output variable.\n","        sigmoid_output = self.__call__(self.x)\n","        output_gradient = input_gradient * sigmoid_output * (1 - sigmoid_output)\n","        return output_gradient\n","    \n","class Model:\n","    # Here we initalize instances of our above-created classes\n","    def __init__(self, input_size, hidden_size, output_size):\n","        self.linear1 = Linear(input_size, hidden_size)\n","        self.relu = ReLU()\n","        self.linear2 = Linear(hidden_size, output_size)\n","        self.sigmoid = Sigmoid()\n","  \n","    # We perform forward prop here, by connecting each layer and activation function together\n","    def __call__(self, x):\n","        l1 = self.linear1(x)\n","        r = self.relu(l1)\n","        l2 = self.linear2(r)\n","        sig = self.sigmoid(l2)\n","        return sig\n","  \n","    # Here we perform backward propagation\n","    def backward(self, loss_gradient):\n","        sigmoid_gradient = self.sigmoid.backward(loss_gradient)\n","        linear2_gradient = self.linear2.backward(sigmoid_gradient)\n","        relu_gradient = self.relu.backward(linear2_gradient)\n","        linear1_gradient = self.linear1.backward(relu_gradient)\n","        return linear1_gradient\n","    \n","    # Updating weights and biases for Linear layers\n","    def update(self, lr):\n","        self.linear2.update(lr)\n","        self.linear1.update(lr)\n","\n","# Simple fit function to perform multiple epochs\n","def fit(loss, model, epochs, lr, bs, x, y):\n","    loss_tracker = []\n","    data_size = x.shape[0]\n","    batch_num = (data_size + bs - 1) // bs\n","    for epoch in range(epochs):\n","        for batch_idx in range(batch_num):\n","            \n","            start_idx = batch_idx * bs\n","            end_idx = min((batch_idx + 1) * bs, data_size)\n","            x_batch = x[start_idx:end_idx]\n","            y_batch = y[start_idx:end_idx]\n","            \n","            y_pred = model(x_batch)\n","            loss_value = loss(y_pred, y_batch)\n","            loss_gradient = loss.backward()\n","            model.backward(loss_gradient)\n","            model.update(lr)\n","            \n","        print(f'Epoch {epoch}, Loss {loss_value},', 'Accuracy', np.round((y == (model(x) >= .5)).mean()*100),'%')\n","        loss_tracker.append(loss(model(x),y))\n","    plt.plot(loss_tracker)\n","\n","# Predicting on validation set\n","def predict(model, x, y):\n","    predictions = model(x)\n","    print('Accuracy on valid set: ', np.round((y == (predictions >= .5)).mean()*100),'%')"]},{"cell_type":"markdown","id":"678de352","metadata":{"papermill":{"duration":0.005541,"end_time":"2023-06-08T10:18:10.370636","exception":false,"start_time":"2023-06-08T10:18:10.365095","status":"completed"},"tags":[]},"source":["**Creating instances of classes and calling functions...**"]},{"cell_type":"code","execution_count":5,"id":"f644f901","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:10.384479Z","iopub.status.busy":"2023-06-08T10:18:10.384022Z","iopub.status.idle":"2023-06-08T10:18:13.528074Z","shell.execute_reply":"2023-06-08T10:18:13.526799Z"},"papermill":{"duration":3.153666,"end_time":"2023-06-08T10:18:13.530514","exception":false,"start_time":"2023-06-08T10:18:10.376848","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss 0.3948559406730051, Accuracy 58.0 %\n","Epoch 1, Loss 0.3235292635699109, Accuracy 87.0 %\n","Epoch 2, Loss 0.2699756697396359, Accuracy 95.0 %\n","Epoch 3, Loss 0.21683990200078707, Accuracy 97.0 %\n","Epoch 4, Loss 0.16633459108733678, Accuracy 98.0 %\n","Epoch 5, Loss 0.1281002494980553, Accuracy 98.0 %\n","Epoch 6, Loss 0.1024322835331865, Accuracy 98.0 %\n","Epoch 7, Loss 0.08511400511466997, Accuracy 98.0 %\n","Epoch 8, Loss 0.07290660099747875, Accuracy 98.0 %\n","Epoch 9, Loss 0.06392817289298819, Accuracy 98.0 %\n","Epoch 10, Loss 0.05704176866978592, Accuracy 98.0 %\n","Epoch 11, Loss 0.05159518856276095, Accuracy 98.0 %\n","Epoch 12, Loss 0.04718566379765532, Accuracy 98.0 %\n","Epoch 13, Loss 0.04354815432699393, Accuracy 98.0 %\n","Epoch 14, Loss 0.040503731688432666, Accuracy 98.0 %\n","Epoch 15, Loss 0.037908509173103073, Accuracy 98.0 %\n","Epoch 16, Loss 0.03568293623834255, Accuracy 98.0 %\n","Epoch 17, Loss 0.03375185890953411, Accuracy 99.0 %\n","Epoch 18, Loss 0.032062451932348794, Accuracy 99.0 %\n","Epoch 19, Loss 0.030573693838746672, Accuracy 99.0 %\n","Accuracy on valid set:  99.0 %\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["loss = MAE()\n","model = Model(input_size, hidden_size, output_size)\n","fit(loss, model, epochs, lr, batch, X_train, y_train)\n","predict(model, X_valid, y_valid)"]},{"cell_type":"markdown","id":"595d9ca6","metadata":{"papermill":{"duration":0.006482,"end_time":"2023-06-08T10:18:13.54398","exception":false,"start_time":"2023-06-08T10:18:13.537498","status":"completed"},"tags":[]},"source":["As we can notice on plot and output above, our model performs quite well on train and valid data."]},{"cell_type":"markdown","id":"ad41bb7f","metadata":{"papermill":{"duration":0.006476,"end_time":"2023-06-08T10:18:13.557203","exception":false,"start_time":"2023-06-08T10:18:13.550727","status":"completed"},"tags":[]},"source":["# PyTorch torch:\n","\n","We will built right now the same model but using fantastic PyTorch, as you will notice it's much simplier and faster but it's essential to know how classes in PyTorch library actually works. "]},{"cell_type":"code","execution_count":6,"id":"a7697bf1","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:13.57327Z","iopub.status.busy":"2023-06-08T10:18:13.572436Z","iopub.status.idle":"2023-06-08T10:18:13.584857Z","shell.execute_reply":"2023-06-08T10:18:13.583607Z"},"papermill":{"duration":0.023101,"end_time":"2023-06-08T10:18:13.587095","exception":false,"start_time":"2023-06-08T10:18:13.563994","status":"completed"},"tags":[]},"outputs":[],"source":["class NNetwork(nn.Module):\n","    # We create instances of required functions to our architecture\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, output_size)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    # In numpy approach we called it __call__ method but here it is forward, but the way it works is similar\n","    def forward(self, x):\n","        l1 = self.linear1(x)\n","        r = self.relu(l1)\n","        l2 = self.linear2(r)\n","        sig = self.sigmoid(l2)\n","        return sig\n","    \n","    # We dont have backward propagation here. PyTorch calculates gradients automatically.\n","    \n","# Simple function to fit using multiple epochs.\n","def torch_fit(loss, model, optim, epochs, bs, lr, x, y):\n","    for epoch in range(epochs):\n","        data_size = x.shape[0]\n","        batch_num = (data_size + bs - 1) // bs\n","        for batch_idx in range(batch_num):\n","            \n","            start_idx = batch_idx * bs\n","            end_idx = min((batch_idx + 1) * bs, data_size)\n","            x_batch = x[start_idx:end_idx]\n","            y_batch = y[start_idx:end_idx]\n","            \n","            # It is necessary to zero our gradients after every epoch, otherwise we would accumulate them.\n","            optim.zero_grad()\n","            y_pred = model(x_batch)\n","            loss_value = loss(y_pred, y_batch)\n","            # Calculating gradients\n","            loss_value.backward()\n","            # Param update\n","            optim.step()\n","            \n","        print(f'Epoch {epoch}, loss {loss_value},', 'accuracy', np.round((y.numpy() == (model(x).detach().numpy() >= .5)).mean()*100),'%')\n","\n","def torch_predict(model, x, y):\n","    model.eval()\n","    predictions = model(x)\n","    print('Accuracy', np.round((y.numpy() == (predictions.detach().numpy() >= .5)).mean()*100),'%')"]},{"cell_type":"markdown","id":"db40a74e","metadata":{"papermill":{"duration":0.006513,"end_time":"2023-06-08T10:18:13.600491","exception":false,"start_time":"2023-06-08T10:18:13.593978","status":"completed"},"tags":[]},"source":["**Creating instances and calling functions...**"]},{"cell_type":"code","execution_count":7,"id":"e0a73c46","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:13.616422Z","iopub.status.busy":"2023-06-08T10:18:13.615974Z","iopub.status.idle":"2023-06-08T10:18:14.79172Z","shell.execute_reply":"2023-06-08T10:18:14.790467Z"},"papermill":{"duration":1.186919,"end_time":"2023-06-08T10:18:14.794242","exception":false,"start_time":"2023-06-08T10:18:13.607323","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, loss 0.46023669838905334, accuracy 89.0 %\n","Epoch 1, loss 0.4006425142288208, accuracy 96.0 %\n","Epoch 2, loss 0.3218463659286499, accuracy 97.0 %\n","Epoch 3, loss 0.24052639305591583, accuracy 97.0 %\n","Epoch 4, loss 0.1761099249124527, accuracy 97.0 %\n","Epoch 5, loss 0.13324280083179474, accuracy 97.0 %\n","Epoch 6, loss 0.10574472695589066, accuracy 97.0 %\n","Epoch 7, loss 0.08745312690734863, accuracy 98.0 %\n","Epoch 8, loss 0.07457593083381653, accuracy 98.0 %\n","Epoch 9, loss 0.06506490707397461, accuracy 98.0 %\n","Epoch 10, loss 0.05778956785798073, accuracy 98.0 %\n","Epoch 11, loss 0.052049264311790466, accuracy 98.0 %\n","Epoch 12, loss 0.04741648584604263, accuracy 98.0 %\n","Epoch 13, loss 0.04360123723745346, accuracy 98.0 %\n","Epoch 14, loss 0.04041097313165665, accuracy 98.0 %\n","Epoch 15, loss 0.037707436829805374, accuracy 98.0 %\n","Epoch 16, loss 0.03538685664534569, accuracy 98.0 %\n","Epoch 17, loss 0.03337917849421501, accuracy 98.0 %\n","Epoch 18, loss 0.03162747249007225, accuracy 98.0 %\n","Epoch 19, loss 0.03008730709552765, accuracy 98.0 %\n","Accuracy 99.0 %\n"]}],"source":["torchLoss = nn.L1Loss()\n","torchModel = NNetwork(input_size, hidden_size, output_size)\n","# Here we use SGD optimizer which updates our parameters in model. We call method parameters() which is inherited from\n","# nn.Module.\n","torchOptimizer = torch.optim.SGD(torchModel.parameters(), lr=lr)\n","    \n","torch_fit(torchLoss, torchModel, torchOptimizer, epochs, batch, lr, X_train_t, y_train_t)\n","torch_predict(torchModel, X_valid_t, y_valid_t)"]},{"cell_type":"markdown","id":"237b82ad","metadata":{"papermill":{"duration":0.006715,"end_time":"2023-06-08T10:18:14.808191","exception":false,"start_time":"2023-06-08T10:18:14.801476","status":"completed"},"tags":[]},"source":["As we can see - that model performs as well as numpy approach."]},{"cell_type":"markdown","id":"e5f5ac0c","metadata":{"papermill":{"duration":0.00683,"end_time":"2023-06-08T10:18:14.822555","exception":false,"start_time":"2023-06-08T10:18:14.815725","status":"completed"},"tags":[]},"source":["**Accessing model weights, biases, architecture...**"]},{"cell_type":"markdown","id":"e7b5db45","metadata":{"papermill":{"duration":0.006803,"end_time":"2023-06-08T10:18:14.836427","exception":false,"start_time":"2023-06-08T10:18:14.829624","status":"completed"},"tags":[]},"source":["We can see matrix of weights and biases for each of our Linear Layer. These are final weights and biases used in predicting on validation set."]},{"cell_type":"code","execution_count":8,"id":"037d7c50","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:14.85325Z","iopub.status.busy":"2023-06-08T10:18:14.852348Z","iopub.status.idle":"2023-06-08T10:18:14.881783Z","shell.execute_reply":"2023-06-08T10:18:14.880568Z"},"papermill":{"duration":0.040917,"end_time":"2023-06-08T10:18:14.884371","exception":false,"start_time":"2023-06-08T10:18:14.843454","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["linear1.weight Parameter containing:\n","tensor([[-0.0263, -0.0340, -0.0218,  ..., -0.0323,  0.0206,  0.0290],\n","        [-0.0322,  0.0063, -0.0066,  ..., -0.0037, -0.0017, -0.0148],\n","        [-0.0135,  0.0267,  0.0157,  ..., -0.0008,  0.0341,  0.0208],\n","        ...,\n","        [ 0.0016,  0.0242,  0.0181,  ..., -0.0114, -0.0228,  0.0079],\n","        [-0.0002,  0.0015,  0.0075,  ..., -0.0098,  0.0271,  0.0289],\n","        [ 0.0354, -0.0197, -0.0044,  ..., -0.0261,  0.0206,  0.0074]],\n","       requires_grad=True)\n","linear1.bias Parameter containing:\n","tensor([ 0.0119, -0.0182,  0.0113,  0.0229,  0.0863, -0.0212,  0.0292,  0.0497,\n","         0.0272,  0.0297,  0.0345,  0.0154,  0.0451, -0.0223, -0.0032,  0.0562,\n","         0.0586,  0.0908, -0.0064,  0.0219,  0.0565, -0.0104,  0.0403,  0.0392,\n","         0.0281,  0.0025, -0.0352,  0.0545, -0.0040,  0.0334,  0.0498,  0.0133],\n","       requires_grad=True)\n","linear2.weight Parameter containing:\n","tensor([[-0.1047,  0.1852, -0.0356, -0.3326,  0.5103, -0.1267,  0.1349, -0.4160,\n","          0.3892,  0.0954, -0.1976, -0.1895, -0.4202,  0.0533,  0.1070,  0.1928,\n","          0.3770,  0.5651, -0.2993, -0.0663,  0.4495, -0.1430, -0.4559,  0.0725,\n","         -0.3847,  0.0387,  0.0063, -0.3535, -0.1807, -0.0926, -0.3854,  0.2050]],\n","       requires_grad=True)\n","linear2.bias Parameter containing:\n","tensor([0.0341], requires_grad=True)\n"]}],"source":["for name, param in torchModel.named_parameters():\n","    print(name, param)"]},{"cell_type":"code","execution_count":9,"id":"7c1af296","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:14.901884Z","iopub.status.busy":"2023-06-08T10:18:14.901102Z","iopub.status.idle":"2023-06-08T10:18:14.91028Z","shell.execute_reply":"2023-06-08T10:18:14.909436Z"},"papermill":{"duration":0.020485,"end_time":"2023-06-08T10:18:14.912427","exception":false,"start_time":"2023-06-08T10:18:14.891942","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<bound method Module.parameters of NNetwork(\n","  (linear1): Linear(in_features=784, out_features=32, bias=True)\n","  (relu): ReLU()\n","  (linear2): Linear(in_features=32, out_features=1, bias=True)\n","  (sigmoid): Sigmoid()\n",")>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["tensor([[-0.0263, -0.0340, -0.0218,  ..., -0.0323,  0.0206,  0.0290],\n","        [-0.0322,  0.0063, -0.0066,  ..., -0.0037, -0.0017, -0.0148],\n","        [-0.0135,  0.0267,  0.0157,  ..., -0.0008,  0.0341,  0.0208],\n","        ...,\n","        [ 0.0016,  0.0242,  0.0181,  ..., -0.0114, -0.0228,  0.0079],\n","        [-0.0002,  0.0015,  0.0075,  ..., -0.0098,  0.0271,  0.0289],\n","        [ 0.0354, -0.0197, -0.0044,  ..., -0.0261,  0.0206,  0.0074]])"]},"metadata":{},"output_type":"display_data"}],"source":["display(torchModel.parameters) # Accessing architecture\n","display(torchModel.linear1.weight.data) # Accessing weights in first hidden layer. We see it is similar to weights above"]},{"cell_type":"markdown","id":"0b37de53","metadata":{"papermill":{"duration":0.007174,"end_time":"2023-06-08T10:18:14.927258","exception":false,"start_time":"2023-06-08T10:18:14.920084","status":"completed"},"tags":[]},"source":["# Multi-class classification:"]},{"cell_type":"markdown","id":"0d477cef","metadata":{"papermill":{"duration":0.007082,"end_time":"2023-06-08T10:18:14.941934","exception":false,"start_time":"2023-06-08T10:18:14.934852","status":"completed"},"tags":[]},"source":["not finished;\n","TO DO;\n","* Create CrossEntropyLoss\n","* Create Softmax"]},{"cell_type":"code","execution_count":10,"id":"7c82d22c","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:14.959511Z","iopub.status.busy":"2023-06-08T10:18:14.958746Z","iopub.status.idle":"2023-06-08T10:18:15.269513Z","shell.execute_reply":"2023-06-08T10:18:15.268355Z"},"papermill":{"duration":0.323167,"end_time":"2023-06-08T10:18:15.272654","exception":false,"start_time":"2023-06-08T10:18:14.949487","status":"completed"},"tags":[]},"outputs":[],"source":["num_classes = 10\n","Xst = torch.Tensor(data.iloc[:proportion,1:].values / 255.)\n","Yst = torch.Tensor(np.eye(num_classes)[data.iloc[:proportion,0].values])\n","Xsv = torch.Tensor(data.iloc[proportion:,1:].values / 255.)\n","Ysv = torch.Tensor(np.eye(num_classes)[data.iloc[proportion:,0].values])"]},{"cell_type":"code","execution_count":11,"id":"93692861","metadata":{"execution":{"iopub.execute_input":"2023-06-08T10:18:15.29067Z","iopub.status.busy":"2023-06-08T10:18:15.289669Z","iopub.status.idle":"2023-06-08T10:18:16.496423Z","shell.execute_reply":"2023-06-08T10:18:16.495085Z"},"papermill":{"duration":1.218624,"end_time":"2023-06-08T10:18:16.49879","exception":false,"start_time":"2023-06-08T10:18:15.280166","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, loss 2.3018083572387695, accuracy 14.0 %\n","Epoch 1, loss 2.300825595855713, accuracy 15.0 %\n","Epoch 2, loss 2.299755811691284, accuracy 16.0 %\n","Epoch 3, loss 2.298585891723633, accuracy 17.0 %\n","Epoch 4, loss 2.2973339557647705, accuracy 18.0 %\n","Epoch 5, loss 2.2959446907043457, accuracy 19.0 %\n","Epoch 6, loss 2.2944486141204834, accuracy 20.0 %\n","Epoch 7, loss 2.2928011417388916, accuracy 21.0 %\n","Epoch 8, loss 2.291002035140991, accuracy 23.0 %\n","Epoch 9, loss 2.289017915725708, accuracy 24.0 %\n","Epoch 10, loss 2.286821126937866, accuracy 25.0 %\n","Epoch 11, loss 2.2844088077545166, accuracy 25.0 %\n","Epoch 12, loss 2.2817578315734863, accuracy 26.0 %\n","Epoch 13, loss 2.278806686401367, accuracy 26.0 %\n","Epoch 14, loss 2.2754933834075928, accuracy 26.0 %\n","Epoch 15, loss 2.2717554569244385, accuracy 27.0 %\n","Epoch 16, loss 2.2675774097442627, accuracy 27.0 %\n","Epoch 17, loss 2.262911796569824, accuracy 27.0 %\n","Epoch 18, loss 2.257718086242676, accuracy 27.0 %\n","Epoch 19, loss 2.2520477771759033, accuracy 27.0 %\n"]}],"source":["class NNetworkMC(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.Softmax(dim=1)\n","  \n","    def forward(self, x):\n","        l1 = self.linear1(x)\n","        r = self.relu(l1)\n","        l2 = self.linear2(r)\n","        sm = self.softmax(l2)\n","        return sm\n","    \n","def Ttorch_fit(loss, model, optim, epochs, bs, lr, x, y):\n","    for epoch in range(epochs):\n","        data_size = x.shape[0]\n","        batch_num = (data_size + bs - 1) // bs\n","        for batch_idx in range(batch_num):\n","            \n","            start_idx = batch_idx * bs\n","            end_idx = min((batch_idx + 1) * bs, data_size)\n","            x_batch = x[start_idx:end_idx]\n","            y_batch = y[start_idx:end_idx]\n","            \n","            optim.zero_grad()\n","            y_pred = model(x_batch)\n","            loss_value = loss(y_pred, y_batch)\n","            loss_value.backward()\n","            optim.step()\n","        print(f'Epoch {epoch}, loss {loss_value},', 'accuracy', np.round((model(x).detach().numpy().argmax(axis=1) == y.detach().numpy().argmax(axis=1)).mean()*100),'%')\n","\n","    \n","TtorchLoss = nn.CrossEntropyLoss()\n","TtorchModel = NNetworkMC(input_size, hidden_size, 10)\n","TtorchOptimizer = torch.optim.SGD(TtorchModel.parameters(), lr=lr)\n","Ttorch_fit(TtorchLoss, TtorchModel, TtorchOptimizer, epochs, batch, lr, Xst, Yst)\n"]},{"cell_type":"code","execution_count":null,"id":"ce54a603","metadata":{"papermill":{"duration":0.007079,"end_time":"2023-06-08T10:18:16.513312","exception":false,"start_time":"2023-06-08T10:18:16.506233","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":28.786042,"end_time":"2023-06-08T10:18:18.82103","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-08T10:17:50.034988","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}